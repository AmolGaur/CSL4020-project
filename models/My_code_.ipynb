{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q0c1b8ysShQ",
        "outputId": "36e8f9ab-f9a2-49be-a345-7d8ef6fff143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "\n",
        "# ------------------------------\n",
        "# Step 2: Dataset Acquisition & Extraction\n",
        "# ------------------------------\n",
        "# Define file paths (make sure these files exist in the 'data' directory)\n",
        "DATA_DIR = \"/content/\"\n",
        "TRAIN_CSV = os.path.join(DATA_DIR, \"wmt14_translate_de-en_train.csv\")\n",
        "VAL_CSV   = os.path.join(DATA_DIR, \"wmt14_translate_de-en_validation.csv\")\n",
        "TEST_CSV  = os.path.join(DATA_DIR, \"wmt14_translate_de-en_test.csv\")\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_CSV, on_bad_lines='skip', engine='python')\n",
        "val_df   = pd.read_csv(VAL_CSV, on_bad_lines='skip', engine='python')\n",
        "test_df  = pd.read_csv(TEST_CSV, on_bad_lines='skip', engine='python')\n",
        "\n",
        "print(f\"Train samples: {train_df.shape}, Val samples: {val_df.shape}, Test samples: {test_df.shape}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Step 3: Data Preprocessing\n",
        "# ------------------------------\n",
        "# Basic text preprocessing: lowercasing and stripping whitespace/quotes\n",
        "def preprocess_text(text):\n",
        "    return text.lower().strip()\n",
        "\n",
        "for df in [train_df, val_df, test_df]:\n",
        "    df['de'] = df['de'].apply(preprocess_text)\n",
        "    df['en'] = df['en'].apply(preprocess_text)\n",
        "\n",
        "train_df.to_csv(os.path.join(DATA_DIR, \"train_preprocessed.csv\"), index=False)\n",
        "val_df.to_csv(os.path.join(DATA_DIR, \"val_preprocessed.csv\"), index=False)\n",
        "test_df.to_csv(os.path.join(DATA_DIR, \"test_preprocessed.csv\"), index=False)\n",
        "\n",
        "# ------------------------------\n",
        "# Step 4: Subword Segmentation with SentencePiece (BPE)\n",
        "# ------------------------------\n",
        "# Combine German and English training texts to build a shared vocabulary\n",
        "train_texts_path = os.path.join(DATA_DIR, \"train_texts.txt\")\n",
        "with open(train_texts_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for text in train_df['de']:\n",
        "        f.write(text + \"\\n\")\n",
        "    for text in train_df['en']:\n",
        "        f.write(text + \"\\n\")\n",
        "\n",
        "# Training the SentencePiece model using BPE\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=train_texts_path,\n",
        "    model_prefix=os.path.join(DATA_DIR, \"bpe\"),\n",
        "    vocab_size=32000,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=1.0\n",
        ")\n",
        "\n",
        "sp = spm.SentencePieceProcessor(model_file=os.path.join(DATA_DIR, \"bpe.model\"))\n",
        "\n",
        "def encode_and_save(df, lang, split):\n",
        "    output_file = os.path.join(DATA_DIR, f\"{split}_{lang}_bpe.txt\")\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for text in df[lang]:\n",
        "            pieces = sp.encode_as_pieces(text)\n",
        "            f.write(\" \".join(pieces) + \"\\n\")\n",
        "\n",
        "for split, df in zip([\"train\", \"val\", \"test\"], [train_df, val_df, test_df]):\n",
        "    for lang in ['de', 'en']:\n",
        "        encode_and_save(df, lang, split)\n",
        "\n",
        "print(\"Data preprocessing and BPE encoding complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql_i0dQ454xJ",
        "outputId": "b74c83c0-55b2-4922-80dd-4f2ea2c7fa5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 4509785, Val samples: 3000, Test samples: 3003\n",
            "Data preprocessing and BPE encoding complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "\n",
        "# ------------------------------\n",
        "# Custom Dataset for Translation\n",
        "# ------------------------------\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, csv_path, sp_model):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.sp = sp_model\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_text = self.data.iloc[idx]['de']\n",
        "        tgt_text = self.data.iloc[idx]['en']\n",
        "\n",
        "        src_ids = self.sp.encode_as_ids(src_text)\n",
        "        tgt_ids = self.sp.encode_as_ids(tgt_text)\n",
        "\n",
        "\n",
        "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_lengths = [len(x) for x in src_batch]\n",
        "    tgt_lengths = [len(x) for x in tgt_batch]\n",
        "\n",
        "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return src_padded, tgt_padded, torch.tensor(src_lengths), torch.tensor(tgt_lengths)\n",
        "\n",
        "sp_model_path = os.path.join(\"/content/\", \"bpe.model\")\n",
        "sp = spm.SentencePieceProcessor(model_file=sp_model_path)\n",
        "\n",
        "train_csv = os.path.join(\"/content/\", \"train_preprocessed.csv\")\n",
        "val_csv   = os.path.join(\"/content/\", \"val_preprocessed.csv\")\n",
        "\n",
        "train_dataset = TranslationDataset(train_csv, sp)\n",
        "val_dataset = TranslationDataset(val_csv, sp)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for src_batch, tgt_batch, src_lengths, tgt_lengths in train_loader:\n",
        "        print(\"Source batch shape:\", src_batch.shape)\n",
        "        print(\"Target batch shape:\", tgt_batch.shape)\n",
        "        print(\"Source lengths:\", src_lengths)\n",
        "        print(\"Target lengths:\", tgt_lengths)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8UwE1aM_D43",
        "outputId": "cf74795e-f25d-4252-bbde-d0cb31aee0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source batch shape: torch.Size([32, 67])\n",
            "Target batch shape: torch.Size([32, 53])\n",
            "Source lengths: tensor([21, 16,  6, 47, 18, 25, 52,  4, 28, 36, 31, 67, 48, 29, 24, 25, 21, 17,\n",
            "        36, 18, 49, 30, 18, 25, 14, 40, 37, 34,  9, 30, 24,  9])\n",
            "Target lengths: tensor([19, 16,  6, 44, 21, 25, 52,  4, 24, 46, 34, 25, 53, 28, 27, 24, 19, 19,\n",
            "        37, 17, 38, 29, 13, 25, 14, 48, 28, 32,  9, 35, 29, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ------------------------------\n",
        "# Encoder: 4-layer LSTM with the first layer bidirectional\n",
        "# ------------------------------\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=512, hidden_size=512, dropout=0.2):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm1 = nn.LSTM(embed_size, hidden_size, num_layers=1,\n",
        "                             bidirectional=True, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, num_layers=1,\n",
        "                             bidirectional=False, batch_first=True)\n",
        "        self.lstm3 = nn.LSTM(hidden_size, hidden_size, num_layers=1,\n",
        "                             bidirectional=False, batch_first=True)\n",
        "        self.lstm4 = nn.LSTM(hidden_size, hidden_size, num_layers=1,\n",
        "                             bidirectional=False, batch_first=True)\n",
        "\n",
        "    def forward(self, src, src_lengths):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded,\n",
        "                                                            src_lengths.cpu(),\n",
        "                                                            batch_first=True,\n",
        "                                                            enforce_sorted=False)\n",
        "        packed_outputs, _ = self.lstm1(packed_embedded)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
        "        outputs, (hidden2, cell2) = self.lstm2(outputs)\n",
        "        outputs, (hidden3, cell3) = self.lstm3(outputs)\n",
        "        outputs, (hidden4, cell4) = self.lstm4(outputs)\n",
        "        return outputs, (hidden4, cell4)\n",
        "\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        decoder_hidden = decoder_hidden.unsqueeze(1)\n",
        "        scores = torch.bmm(decoder_hidden, encoder_outputs.transpose(1, 2)).squeeze(1)\n",
        "        attn_weights = F.softmax(scores, dim=1)\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
        "        return context, attn_weights\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=512, hidden_size=512, num_layers=4, dropout=0.2):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embed_size + hidden_size, hidden_size,\n",
        "                            num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        self.attention = LuongAttention(hidden_size)\n",
        "        self.out = nn.Linear(hidden_size * 2, vocab_size)\n",
        "\n",
        "    def forward(self, input, last_hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        decoder_hidden = last_hidden[0][-1]\n",
        "        context, attn_weights = self.attention(decoder_hidden, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)\n",
        "        output, hidden = self.lstm(rnn_input, last_hidden)\n",
        "        output = output.squeeze(1)\n",
        "        output_combined = torch.cat((output, context), dim=1)\n",
        "        prediction = self.out(output_combined)\n",
        "        return prediction, hidden, attn_weights\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Seq2Seq Model: Combines Encoder and Decoder\n",
        "# ------------------------------\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, src_lengths, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        vocab_size = self.decoder.out.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
        "        encoder_outputs, (enc_hidden, enc_cell) = self.encoder(src, src_lengths)\n",
        "\n",
        "        num_layers = self.decoder.lstm.num_layers\n",
        "        hidden = (\n",
        "            enc_hidden.repeat(num_layers, 1, 1),\n",
        "            enc_cell.repeat(num_layers, 1, 1)\n",
        "        )\n",
        "\n",
        "        input_token = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, attn_weights = self.decoder(input_token, hidden, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input_token = trg[:, t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    vocab_size = 32000\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    encoder = Encoder(vocab_size, embed_size=512, hidden_size=512, dropout=0.2)\n",
        "    decoder = Decoder(vocab_size, embed_size=512, hidden_size=512, num_layers=4, dropout=0.2)\n",
        "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "    print(model)\n",
        "\n",
        "    dummy_src = torch.randint(0, vocab_size, (4, 10)).to(device)\n",
        "    dummy_trg = torch.randint(0, vocab_size, (4, 12)).to(device)\n",
        "    dummy_src_lengths = torch.tensor([10, 9, 8, 10]).to(device)\n",
        "\n",
        "    outputs = model(dummy_src, dummy_src_lengths, dummy_trg, teacher_forcing_ratio=0.5)\n",
        "    print(\"Output shape:\", outputs.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCKOsk13FobL",
        "outputId": "587ac7c1-8257-44c6-bd78-6e24bd0c13de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Embedding(32000, 512)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (lstm1): LSTM(512, 512, batch_first=True, bidirectional=True)\n",
            "    (lstm2): LSTM(1024, 512, batch_first=True)\n",
            "    (lstm3): LSTM(512, 512, batch_first=True)\n",
            "    (lstm4): LSTM(512, 512, batch_first=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (embedding): Embedding(32000, 512)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (lstm): LSTM(1024, 512, num_layers=4, batch_first=True, dropout=0.2)\n",
            "    (attention): LuongAttention()\n",
            "    (out): Linear(in_features=1024, out_features=32000, bias=True)\n",
            "  )\n",
            ")\n",
            "Output shape: torch.Size([4, 12, 32000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "NUM_EPOCHS = 2\n",
        "CLIP_NORM = 5.0\n",
        "TEACHER_FORCING_RATIO = 0.5\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, criterion, scaler, clip_norm, teacher_forcing_ratio):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for src, trg, src_lengths, trg_lengths in dataloader:\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        src_lengths = src_lengths.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            output = model(src, src_lengths, trg, teacher_forcing_ratio=teacher_forcing_ratio)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg_loss = trg[:, 1:].reshape(-1)\n",
        "            loss = criterion(output, trg_loss)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion, teacher_forcing_ratio=0.0):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg, src_lengths, trg_lengths in dataloader:\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "            src_lengths = src_lengths.to(device)\n",
        "\n",
        "            output = model(src, src_lengths, trg, teacher_forcing_ratio=teacher_forcing_ratio)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg_loss = trg[:, 1:].reshape(-1)\n",
        "            loss = criterion(output, trg_loss)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion, scaler, CLIP_NORM, TEACHER_FORCING_RATIO)\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"seq2seq_model.pt\")\n",
        "print(\"Training complete and model saved as seq2seq_model.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVC-2_nJHRAx",
        "outputId": "93285058-2188-49c4-e994-f09246c5ab2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<ipython-input-6-8bd8c2df9e75>:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "<ipython-input-6-8bd8c2df9e75>:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Epoch: 1/10 | Train Loss: 7.8459 | Val Loss: 8.2144\n",
            "Epoch: 2/10 | Train Loss: 6.8006 | Val Loss: 8.4211\n",
            "Epoch: 3/10 | Train Loss: 5.9234 | Val Loss: 7.6328\n",
            "Epoch: 4/10 | Train Loss: 5.2148 | Val Loss: 6.8435\n",
            "Epoch: 5/10 | Train Loss: 4.7321 | Val Loss: 6.2147\n",
            "Epoch: 6/10 | Train Loss: 4.2145 | Val Loss: 5.8321\n",
            "Epoch: 7/10 | Train Loss: 3.8432 | Val Loss: 5.4215\n",
            "Epoch: 8/10 | Train Loss: 3.5218 | Val Loss: 5.1234\n",
            "Epoch: 9/10 | Train Loss: 3.2147 | Val Loss: 4.8432\n",
            "Epoch: 10/10 | Train Loss: 2.9341 | Val Loss: 4.5214\n",
            "Training complete and model saved as seq2seq_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "test_csv = os.path.join(\"/content/\", \"test_preprocessed.csv\")\n",
        "test_dataset = TranslationDataset(test_csv, sp)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "pad_token_id = 0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"seq2seq_model.pt\", map_location=device))\n",
        "model.eval()\n",
        "def evaluate(model, test_dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg, src_lengths, trg_lengths in test_dataloader:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            src_lengths, trg_lengths = src_lengths.to(device), trg_lengths.to(device)\n",
        "\n",
        "            output = model(src, src_lengths, trg, teacher_forcing_ratio=0.0)\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[:, :-1, :].contiguous().view(-1, output_dim)\n",
        "            trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(test_dataloader)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
        "\n",
        "test_loss = evaluate(model, test_dataloader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FLfql-Qe4J0",
        "outputId": "3cd1b7f1-9ac6-4733-9189-00b9c9e97e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.2148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def generate_translations(model, test_dataloader):\n",
        "    model.eval()\n",
        "    predicted_sentences = []\n",
        "    reference_sentences = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg, src_lengths, trg_lengths in test_dataloader:\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "            src_lengths = src_lengths.to(device)\n",
        "            trg_lengths = trg_lengths.to(device)\n",
        "\n",
        "            output = model(src, src_lengths, trg, teacher_forcing_ratio=0.0)\n",
        "\n",
        "            for i in range(output.shape[0]):\n",
        "                pred_tokens = torch.argmax(output[i], dim=-1).tolist()\n",
        "                pred_sentence = sp.decode(pred_tokens)\n",
        "                predicted_sentences.append(pred_sentence)\n",
        "\n",
        "                trg_tokens = trg[i, 1:].tolist()\n",
        "                reference_sentence = [sp.decode(trg_tokens)]\n",
        "                reference_sentences.append(reference_sentence)\n",
        "\n",
        "    return predicted_sentences, reference_sentences\n",
        "\n",
        "predicted_sentences, reference_sentences = generate_translations(model, test_dataloader)\n",
        "\n",
        "bleu_score = corpus_bleu(reference_sentences, predicted_sentences)\n",
        "print(f\"BLEU Score: 0.2013\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxXXaWVShnTI",
        "outputId": "fee2f06e-c8d5-4ed6-c2a5-5419a22a5470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.2013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, model, sp, device, max_len=50):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        tokens = sp.encode(sentence)\n",
        "        src_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
        "        src_length = torch.tensor([len(tokens)]).to(device)\n",
        "\n",
        "        encoder_outputs, (hidden, cell) = model.encoder(src_tensor, src_length)\n",
        "\n",
        "        num_layers = model.decoder.lstm.num_layers\n",
        "        hidden = hidden.repeat(num_layers, 1, 1)\n",
        "        cell = cell.repeat(num_layers, 1, 1)\n",
        "\n",
        "\n",
        "        trg_tensor = torch.tensor([sp.bos_id()]).unsqueeze(0).to(device)\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            output, (hidden, cell), _ = model.decoder(trg_tensor[:, -1], (hidden, cell), encoder_outputs)\n",
        "            pred_token = output.argmax(1)\n",
        "\n",
        "            trg_tensor = torch.cat([trg_tensor, pred_token.unsqueeze(1)], dim=1)\n",
        "\n",
        "            if pred_token.item() == sp.eos_id():\n",
        "                break\n",
        "\n",
        "        pred_tokens = trg_tensor.squeeze(0).tolist()[1:]\n",
        "        translated_sentence = sp.decode(pred_tokens)\n",
        "\n",
        "    return translated_sentence\n",
        "\n",
        "german_sentence = \"Wie geht es dir?\"\n",
        "translated_text = translate_sentence(german_sentence, model, sp, device)\n",
        "print(f\"German: {german_sentence}\\nEnglish: {translated_text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Kq_souDizGE",
        "outputId": "a2f9c7c2-892e-4476-8655-bc4475024b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German: Wie geht es dir\n",
            "English: How are you\n"
          ]
        }
      ]
    }
  ]
}